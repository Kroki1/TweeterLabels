{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b6e324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sys \n",
    "from tqdm import tqdm \n",
    "import os \n",
    "from random import sample \n",
    "from annoy import AnnoyIndex \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay \n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score \n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38f1f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = './Data/train.csv'\n",
    "train_enriched_file = './Data/train_enriched.csv'\n",
    "test_file = './Data/test.csv'\n",
    "test_enriched = './Data/test_enriched.csv'\n",
    "label_file = './Data/sample_submission.csv'\n",
    "embeddings_dim = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a894852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_enriched_file, encoding='utf-8')\n",
    "df_test = pd.read_csv(test_file,encoding='utf-8')\n",
    "df_test_enr = pd.read_csv(test_enriched,encoding='utf-8')\n",
    "df_true = pd.read_csv('./Data/submission.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e551e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mats\\AppData\\Roaming\\Python\\Python37\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\mats\\AppData\\Roaming\\Python\\Python37\\site-packages\\huggingface_hub\\snapshot_download.py:11: FutureWarning: snapshot_download.py has been made private and will no longer be available from version 0.11. Please use `from huggingface_hub import snapshot_download` to import the only public function in this module. Other members of the file may be changed without a deprecation notice.\n",
      "  FutureWarning,\n",
      "C:\\Users\\mats\\AppData\\Roaming\\Python\\Python37\\site-packages\\huggingface_hub\\file_download.py:563: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer \n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "748824c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    emb = model.encode(text, convert_to_tensor=True).tolist()\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44820aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_tweet(testdf,targetdf):\n",
    "          \n",
    "    tweets = testdf['emb'].to_list()\n",
    "    text = testdf['text'].to_list()\n",
    "    test_ids = testdf['id'].to_list()\n",
    "    df_pred = pd.DataFrame()\n",
    "          \n",
    "    for tweet,tx,t_id in zip(tweets,text,test_ids):\n",
    "              \n",
    "        df_temp = pd.DataFrame()\n",
    "        search_res = annoy_index.get_nns_by_vector(tweet,n=1,search_k=-1,include_distances=False)\n",
    "        d = {t_id: [t_id, tx, search_res[0]]}\n",
    "        df_temp = pd.DataFrame.from_dict(d, orient = 'index', columns=['test_id','text', 'target_id'])\n",
    "        df_pred = pd.concat([df_pred,df_temp])\n",
    "          \n",
    "          \n",
    "    df_pred = df_pred.merge(targetdf[['id','target']], right_on='id', left_on='target_id', how='left')\n",
    "                                  \n",
    "    #mergedf = targetdf[['id','target']]\n",
    "          \n",
    "    return df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace58b78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_words_count</th>\n",
       "      <th>Tweet_len</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>hash_count</th>\n",
       "      <th>@_count</th>\n",
       "      <th>URL_count</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>dis%</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>keyword_clean</th>\n",
       "      <th>newtext</th>\n",
       "      <th>tx_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>deed reason #earthquak may allah forgiv</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>deed reason #earthquak may allah forgiv</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>forest fire near la rong sask. canada</td>\n",
       "      <td>nokeyword</td>\n",
       "      <td>forest fire near la rong sask. canada</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     keyword                                               text  target  \\\n",
       "0   1  no_keyword  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1   4  no_keyword             Forest fire near La Ronge Sask. Canada       1   \n",
       "\n",
       "   word_count  unique_words_count  Tweet_len  special_chars_count  hash_count  \\\n",
       "0          13                  13         69                    1           1   \n",
       "1           7                   7         38                    1           0   \n",
       "\n",
       "   @_count  URL_count  sentiment  subjectivity        dis%  \\\n",
       "0        0          0        0.0           0.0  no_keyword   \n",
       "1        0          0        0.1           0.4  no_keyword   \n",
       "\n",
       "                                text_clean keyword_clean  \\\n",
       "0  deed reason #earthquak may allah forgiv     nokeyword   \n",
       "1    forest fire near la rong sask. canada     nokeyword   \n",
       "\n",
       "                                    newtext  \\\n",
       "0  deed reason #earthquak may allah forgiv    \n",
       "1    forest fire near la rong sask. canada    \n",
       "\n",
       "                                              tx_key  \n",
       "0  Our Deeds are the Reason of this #earthquake M...  \n",
       "1            Forest fire near La Ronge Sask. Canada   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tx_key'] = df['text'] + ' ' + df['keyword'].apply(lambda x: x if x != 'no_keyword' else '')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b2379",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emb'] = df['text'].apply(lambda t: encode(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7421dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('./Data/train_emb.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff4954",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test_enr['tx_key'] = df_test_enr['text'] + ' ' + df_test_enr['keyword'].apply(lambda x: x if x != 'no_keyword' else '')\n",
    "df_test_enr.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8533358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_enr['emb'] = df_test_enr['text'].apply(lambda t: encode(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac59b5",
   "metadata": {},
   "source": [
    "## build annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a995a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = df['emb'].to_list()\n",
    "tweets_ids = df['id'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e6966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "annoy_index = AnnoyIndex(embeddings_dim, 'angular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c9652",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet_id, embedding in zip(tweets_ids,embeddings):\n",
    "    if len(embedding) != embeddings_dim:\n",
    "        print('wrong dim lenght')\n",
    "        continue \n",
    "    annoy_index.add_item(tweet_id,embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d32c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "annoy_index.build(100) #,n_jobs=-1)\n",
    "annoy_index.save('./Data/annoy_index.ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46f28ac",
   "metadata": {},
   "source": [
    "## load built annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da3172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annoy_index = AnnoyIndex(embeddings_dim, 'angular')\n",
    "# annoy_index.load('./Data/annoy_index.ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b6af16",
   "metadata": {},
   "source": [
    "## search for similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcbcefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = label_tweet(df_test_enr,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b297723",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ac24e",
   "metadata": {},
   "source": [
    "## <font color = 'dark green'> metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7028a9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = df_pred['target']\n",
    "y = df_true['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e62d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y,y_pred)\n",
    "f1 = f1_score(y,y_pred,average='macro')\n",
    "precision = precision_score(y,y_pred,average='macro')\n",
    "recall = recall_score(y,y_pred,average='macro')\n",
    "\n",
    "print(f'Accuracy  {accuracy}')\n",
    "print(f'F1        {f1}')\n",
    "print(f'Precision {precision}')\n",
    "print(f'Recall    {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2b1523",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488c4923",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y, y_pred, normalize='all')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61af8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
